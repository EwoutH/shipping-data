{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Merge daily dataframes to one single dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:24.136209Z",
     "end_time": "2023-04-02T17:49:24.388475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 dates included (2022-10-31 to 2022-11-22).\n"
     ]
    }
   ],
   "source": [
    "# Define the date range\n",
    "start_date = '2022-10-31'\n",
    "end_date = '2022-11-22'\n",
    "\n",
    "# Create a list of dates in YYYY-MM-DD format\n",
    "dates = pd.date_range(start_date, end_date).strftime(\"%Y-%m-%d\").tolist()\n",
    "print(f\"{len(dates)} dates included ({start_date} to {end_date}).\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:24.388475Z",
     "end_time": "2023-04-02T17:49:24.392815Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Read the pickle files as dicts and add them to a list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Loop through the dates and read the pickle files. Each pickle file contains a list of dictionaries, each dictionary contains the details of one route.\n",
    "processed_list = []\n",
    "missing = 0\n",
    "for date in dates:\n",
    "    # Read the pickle for each date. It contains a list of dictionaries, each dictionary contains the details of one harbor combination.\n",
    "    try:\n",
    "        with open(f'../pickles/routescanner_daily_v2/connections_{date}.pickle', 'rb') as f:\n",
    "            results_list = pickle.load(f)\n",
    "    except:\n",
    "        missing += 1\n",
    "        print(f\"Data for {date} missing!\")\n",
    "\n",
    "    # Unpack the list of dictionaries. Each dictionary contains the details of one route. The \"Key\" key contains another dictionary with the route details. Flatten it into the main dictionary. Put the new items at the beginning of the dictionary.\n",
    "    for result in results_list:\n",
    "        # Remove the \"hash\" and \"requestId\" keys, they are not needed.\n",
    "        for key_name in [\"hash\", \"requestId\"]:\n",
    "            result.pop(key_name)\n",
    "\n",
    "        # Flatten the information in the \"origin\", \"destination\" dictionary.\n",
    "        for dict_name in [\"origin\", \"destination\"]:\n",
    "            new_dict = result[dict_name]\n",
    "            # Add the dict_name to the keys of the new dictionary.\n",
    "            new_dict = {f\"{dict_name}_{key}\": value for key, value in new_dict.items() if key != \"type\"}\n",
    "            result = (new_dict | result)\n",
    "            result.pop(dict_name)\n",
    "\n",
    "        # Create a dictionary with the details that's identical for all routes in the list.\n",
    "        non_route_specific_results = result.copy()\n",
    "        non_route_specific_results.pop(\"voyages\")\n",
    "\n",
    "        # Loop through the list of routes, create a new dictionary for each route and append it to the list.\n",
    "        routes_details_list = result['voyages']\n",
    "        for route in routes_details_list:\n",
    "            # Merge the non-route-specific details with the route-specific details.\n",
    "            new_dict = non_route_specific_results.copy()\n",
    "            new_dict[\"NumberOfLegs\"] = len(route[\"legs\"])\n",
    "            new_dict = (new_dict | route)\n",
    "            new_dict[\"ScrapingDate\"] = date\n",
    "            processed_list.append(new_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:24.392815Z",
     "end_time": "2023-04-02T17:49:25.869610Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create a single dataframe from the list of dictionaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of routes: 22349, spread over 23 days.\n",
      "7038 identical rows dropped, 31.49% of the total number of rows, with 15311 remaining.\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe from the list of dictionaries\n",
    "df = pd.DataFrame(processed_list)\n",
    "\n",
    "# Convert travel time in minutes to travel time in hours.\n",
    "df['totalTravelTimeInMinutes'] = df['totalTravelTimeInMinutes'] / 60\n",
    "\n",
    "# Move the second last column to the beginning of the dataframe\n",
    "df = df[[df.columns[-2]] + df.columns[:-2].tolist()]\n",
    "\n",
    "print(f\"Total number of routes: {len(df)}, spread over {len(dates)-missing} days.\")\n",
    "\n",
    "# Assign the optimal data types to the columns.\n",
    "df = df.convert_dtypes()\n",
    "\n",
    "# Drop rows which are identical, except for the ScrapingDate column.\n",
    "rows_before = len(df)\n",
    "columns_to_check = [col for col in df.columns.to_list() if col not in [\"ScrapingDate\", \"legs\", \"transferCo2EmissionsInKg\", \"hash\", \"requestId\"]]\n",
    "\n",
    "# Convert dict to strings in the DataFrame\n",
    "for col in columns_to_check:\n",
    "    if df[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "        df[col] = df[col].apply(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "df = df.drop_duplicates(subset=columns_to_check, keep='first')\n",
    "\n",
    "# Print the number of identical rows dropped.\n",
    "print(f\"{rows_before - len(df)} identical rows dropped, {1-(len(df)/rows_before):.2%} of the total number of rows, with {len(df)} remaining.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:25.869909Z",
     "end_time": "2023-04-02T17:49:26.023313Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Rename columns\n",
    "Translate column names following https://docs.google.com/spreadsheets/d/1MkXMOXTt2jIEqUUjSN4Zx1sN-ISponH9DnHL_O1X_l4/edit#gid=412081908"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       Combined       Format_unit       Maersk            MSC   \n0  ScrapingDate  str (YYYY-MM-DD)          NaN   ScrapingDate  \\\n1  ScrapingSite        Name (str)       Maersk            MSC   \n2        Origin   UNLOCCODE (str)       Origin         Origin   \n3   Destination   UNLOCCODE (str)  Destination    Destination   \n4    OriginName               str          NaN  PortOfLoading   \n\n         Routescanner  \n0        ScrapingDate  \n1        Routescanner  \n2       origin_locode  \n3  destination_locode  \n4         origin_name  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Combined</th>\n      <th>Format_unit</th>\n      <th>Maersk</th>\n      <th>MSC</th>\n      <th>Routescanner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ScrapingDate</td>\n      <td>str (YYYY-MM-DD)</td>\n      <td>NaN</td>\n      <td>ScrapingDate</td>\n      <td>ScrapingDate</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ScrapingSite</td>\n      <td>Name (str)</td>\n      <td>Maersk</td>\n      <td>MSC</td>\n      <td>Routescanner</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Origin</td>\n      <td>UNLOCCODE (str)</td>\n      <td>Origin</td>\n      <td>Origin</td>\n      <td>origin_locode</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Destination</td>\n      <td>UNLOCCODE (str)</td>\n      <td>Destination</td>\n      <td>Destination</td>\n      <td>destination_locode</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OriginName</td>\n      <td>str</td>\n      <td>NaN</td>\n      <td>PortOfLoading</td>\n      <td>origin_name</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read translation table from Google Sheets\n",
    "SHEET_ID = '1MkXMOXTt2jIEqUUjSN4Zx1sN-ISponH9DnHL_O1X_l4'\n",
    "SHEET_NAME = 'Combined'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "name_df = pd.read_csv(url, header=0, on_bad_lines='skip')\n",
    "name_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:26.023313Z",
     "end_time": "2023-04-02T17:49:26.349239Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  ScrapingDate  DestinationName                 destination_location   \n0   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}  \\\n1   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n2   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n3   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n4   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n\n  Destination     OriginName                        origin_location Origin   \n0       NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI  \\\n1       NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n2       NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n3       BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n4       BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n\n   totalResults  NumberOfLegs  EstimatedTotalTransitTimeHours   \n0             3             3                      748.533333  \\\n1             3             3                      511.266667   \n2             3             3                      470.966667   \n3             2             2                           655.5   \n4             2             2                          466.45   \n\n   TotalDistanceMeters  totalCo2EmissionsInKg     EstimatedDepartureTime   \n0             12894138                   1150  2022-11-03T22:30:00-03:00  \\\n1             13132075                   1860  2022-11-06T13:32:30-05:00   \n2             12962474                   1885  2022-11-06T13:32:30-05:00   \n3             12629105                   1045  2022-11-03T22:30:00-03:00   \n4             12804509                   1750  2022-11-06T13:32:30-05:00   \n\n        EstimatedArrivalTime TotalCO2EmissionsKg   \n0  2022-12-05T07:02:14+01:00            [15, 15]  \\\n1  2022-11-28T02:49:28+01:00            [15, 15]   \n2  2022-11-26T10:30:48+01:00            [15, 15]   \n3  2022-12-01T10:00:00+01:00                [15]   \n4  2022-11-26T06:00:00+01:00                [15]   \n\n                                                Legs  \n0  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n1  [{'origin': {'type': 'locode', 'name': 'Port o...  \n2  [{'origin': {'type': 'locode', 'name': 'Port o...  \n3  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n4  [{'origin': {'type': 'locode', 'name': 'Port o...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ScrapingDate</th>\n      <th>DestinationName</th>\n      <th>destination_location</th>\n      <th>Destination</th>\n      <th>OriginName</th>\n      <th>origin_location</th>\n      <th>Origin</th>\n      <th>totalResults</th>\n      <th>NumberOfLegs</th>\n      <th>EstimatedTotalTransitTimeHours</th>\n      <th>TotalDistanceMeters</th>\n      <th>totalCo2EmissionsInKg</th>\n      <th>EstimatedDepartureTime</th>\n      <th>EstimatedArrivalTime</th>\n      <th>TotalCO2EmissionsKg</th>\n      <th>Legs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>748.533333</td>\n      <td>12894138</td>\n      <td>1150</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-05T07:02:14+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>511.266667</td>\n      <td>13132075</td>\n      <td>1860</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-28T02:49:28+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>470.966667</td>\n      <td>12962474</td>\n      <td>1885</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T10:30:48+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>655.5</td>\n      <td>12629105</td>\n      <td>1045</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-01T10:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>466.45</td>\n      <td>12804509</td>\n      <td>1750</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T06:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with the Routescanner values as keys and the Combined values as values.\n",
    "name_dict = dict(zip(name_df['Routescanner'], name_df['Combined']))\n",
    "\n",
    "# Rename the columns of df using the dictionary.\n",
    "df = df.rename(columns=name_dict)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:26.349239Z",
     "end_time": "2023-04-02T17:49:26.376171Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Save the dataframe to a pickle file.\n",
    "filename = \"routescanner_v2_connections_combined\"\n",
    "df.to_pickle(f\"../pickles/{filename}.pickle\")\n",
    "df.to_csv(f\"../data/{filename}.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:26.376171Z",
     "end_time": "2023-04-02T17:49:28.787812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  ScrapingDate  DestinationName                 destination_location   \n0   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}  \\\n1   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n2   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n3   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n4   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n\n  Destination     OriginName                        origin_location Origin   \n0       NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI  \\\n1       NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n2       NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n3       BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n4       BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}  CLARI   \n\n   totalResults  NumberOfLegs  EstimatedTotalTransitTimeHours   \n0             3             3                      748.533333  \\\n1             3             3                      511.266667   \n2             3             3                      470.966667   \n3             2             2                           655.5   \n4             2             2                          466.45   \n\n   TotalDistanceMeters  totalCo2EmissionsInKg     EstimatedDepartureTime   \n0             12894138                   1150  2022-11-03T22:30:00-03:00  \\\n1             13132075                   1860  2022-11-06T13:32:30-05:00   \n2             12962474                   1885  2022-11-06T13:32:30-05:00   \n3             12629105                   1045  2022-11-03T22:30:00-03:00   \n4             12804509                   1750  2022-11-06T13:32:30-05:00   \n\n        EstimatedArrivalTime TotalCO2EmissionsKg   \n0  2022-12-05T07:02:14+01:00            [15, 15]  \\\n1  2022-11-28T02:49:28+01:00            [15, 15]   \n2  2022-11-26T10:30:48+01:00            [15, 15]   \n3  2022-12-01T10:00:00+01:00                [15]   \n4  2022-11-26T06:00:00+01:00                [15]   \n\n                                                Legs  \n0  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n1  [{'origin': {'type': 'locode', 'name': 'Port o...  \n2  [{'origin': {'type': 'locode', 'name': 'Port o...  \n3  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n4  [{'origin': {'type': 'locode', 'name': 'Port o...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ScrapingDate</th>\n      <th>DestinationName</th>\n      <th>destination_location</th>\n      <th>Destination</th>\n      <th>OriginName</th>\n      <th>origin_location</th>\n      <th>Origin</th>\n      <th>totalResults</th>\n      <th>NumberOfLegs</th>\n      <th>EstimatedTotalTransitTimeHours</th>\n      <th>TotalDistanceMeters</th>\n      <th>totalCo2EmissionsInKg</th>\n      <th>EstimatedDepartureTime</th>\n      <th>EstimatedArrivalTime</th>\n      <th>TotalCO2EmissionsKg</th>\n      <th>Legs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>748.533333</td>\n      <td>12894138</td>\n      <td>1150</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-05T07:02:14+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>511.266667</td>\n      <td>13132075</td>\n      <td>1860</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-28T02:49:28+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>470.966667</td>\n      <td>12962474</td>\n      <td>1885</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T10:30:48+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>655.5</td>\n      <td>12629105</td>\n      <td>1045</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-01T10:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>466.45</td>\n      <td>12804509</td>\n      <td>1750</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T06:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"../pickles/routescanner_v2_connections_combined.pickle\").head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T17:49:28.787812Z",
     "end_time": "2023-04-02T17:49:29.875134Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
