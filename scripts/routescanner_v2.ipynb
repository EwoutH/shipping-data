{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Merge daily dataframes to one single dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:22:24.702687Z",
     "end_time": "2023-04-02T13:22:25.007874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 dates included (2022-10-31 to 2022-11-22).\n"
     ]
    }
   ],
   "source": [
    "# Define the date range\n",
    "start_date = '2022-10-31'\n",
    "end_date = '2022-11-22'\n",
    "\n",
    "# Create a list of dates in YYYY-MM-DD format\n",
    "dates = pd.date_range(start_date, end_date).strftime(\"%Y-%m-%d\").tolist()\n",
    "print(f\"{len(dates)} dates included ({start_date} to {end_date}).\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:22:25.007874Z",
     "end_time": "2023-04-02T13:22:25.023732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Loop through the dates and read the pickle files. Each pickle file contains a list of dictionaries, each dictionary contains the details of one route.\n",
    "processed_list = []\n",
    "missing = 0\n",
    "for date in dates:\n",
    "    # Read the pickle for each date. It contains a list of dictionaries, each dictionary contains the details of one harbor combination.\n",
    "    try:\n",
    "        with open(f'../pickles/routescanner_daily_v2/connections_{date}.pickle', 'rb') as f:\n",
    "            results_list = pickle.load(f)\n",
    "    except:\n",
    "        missing += 1\n",
    "        print(f\"Data for {date} missing!\")\n",
    "\n",
    "    # Unpack the list of dictionaries. Each dictionary contains the details of one route. The \"Key\" key contains another dictionary with the route details. Flatten it into the main dictionary. Put the new items at the beginning of the dictionary.\n",
    "    for result in results_list:\n",
    "        # Remove the \"hash\" and \"requestId\" keys, they are not needed.\n",
    "        for key_name in [\"hash\", \"requestId\"]:\n",
    "            result.pop(key_name)\n",
    "\n",
    "        # Flatten the information in the \"origin\", \"destination\" dictionary.\n",
    "        for dict_name in [\"origin\", \"destination\"]:\n",
    "            new_dict = result[dict_name]\n",
    "            # Add the dict_name to the keys of the new dictionary.\n",
    "            new_dict = {f\"{dict_name}_{key}\": value for key, value in new_dict.items() if key != \"type\"}\n",
    "            result = (new_dict | result)\n",
    "            result.pop(dict_name)\n",
    "\n",
    "        # Create a dictionary with the details that's identical for all routes in the list.\n",
    "        non_route_specific_results = result.copy()\n",
    "        non_route_specific_results.pop(\"voyages\")\n",
    "\n",
    "        # Loop through the list of routes, create a new dictionary for each route and append it to the list.\n",
    "        routes_details_list = result['voyages']\n",
    "        for route in routes_details_list:\n",
    "            # Merge the non-route-specific details with the route-specific details.\n",
    "            new_dict = non_route_specific_results.copy()\n",
    "            new_dict[\"NumberOfLegs\"] = len(route[\"legs\"])\n",
    "            new_dict = (new_dict | route)\n",
    "            new_dict[\"ScrapingDate\"] = date\n",
    "            processed_list.append(new_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:22:25.023732Z",
     "end_time": "2023-04-02T13:22:26.545870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of routes: 22349, spread over 23 days.\n",
      "7038 identical rows dropped, 31.49% of the total number of rows, with 15311 remaining.\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe from the list of dictionaries\n",
    "df = pd.DataFrame(processed_list)\n",
    "\n",
    "# Move the second last column to the beginning of the dataframe\n",
    "df = df[[df.columns[-2]] + df.columns[:-2].tolist()]\n",
    "\n",
    "print(f\"Total number of routes: {len(df)}, spread over {len(dates)-missing} days.\")\n",
    "\n",
    "# Assign the optimal data types to the columns.\n",
    "df = df.convert_dtypes()\n",
    "\n",
    "# Drop rows which are identical, except for the ScrapingDate column.\n",
    "rows_before = len(df)\n",
    "columns_to_check = [col for col in df.columns.to_list() if col not in [\"ScrapingDate\", \"legs\", \"transferCo2EmissionsInKg\", \"hash\", \"requestId\"]]\n",
    "\n",
    "# Convert dict to strings in the DataFrame\n",
    "for col in columns_to_check:\n",
    "    if df[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "        df[col] = df[col].apply(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "df = df.drop_duplicates(subset=columns_to_check, keep='first')\n",
    "\n",
    "# Print the number of identical rows dropped.\n",
    "print(f\"{rows_before - len(df)} identical rows dropped, {1-(len(df)/rows_before):.2%} of the total number of rows, with {len(df)} remaining.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:22:26.561828Z",
     "end_time": "2023-04-02T13:22:26.723123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  ScrapingDate destination_name                 destination_location  \\\n0   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n1   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n2   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n3   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n4   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n\n  destination_locode    origin_name                        origin_location  \\\n0              NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n1              NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n2              NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n3              BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n4              BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n\n  origin_locode  totalResults  NumberOfLegs  totalTravelTimeInMinutes  \\\n0         CLARI             3             3                     44912   \n1         CLARI             3             3                     30676   \n2         CLARI             3             3                     28258   \n3         CLARI             2             2                     39330   \n4         CLARI             2             2                     27987   \n\n   totalDistanceInMeters  totalCo2EmissionsInKg                voyageStart  \\\n0               12894138                   1150  2022-11-03T22:30:00-03:00   \n1               13132075                   1860  2022-11-06T13:32:30-05:00   \n2               12962474                   1885  2022-11-06T13:32:30-05:00   \n3               12629105                   1045  2022-11-03T22:30:00-03:00   \n4               12804509                   1750  2022-11-06T13:32:30-05:00   \n\n                   voyageEnd transferCo2EmissionsInKg  \\\n0  2022-12-05T07:02:14+01:00                 [15, 15]   \n1  2022-11-28T02:49:28+01:00                 [15, 15]   \n2  2022-11-26T10:30:48+01:00                 [15, 15]   \n3  2022-12-01T10:00:00+01:00                     [15]   \n4  2022-11-26T06:00:00+01:00                     [15]   \n\n                                                legs  \n0  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n1  [{'origin': {'type': 'locode', 'name': 'Port o...  \n2  [{'origin': {'type': 'locode', 'name': 'Port o...  \n3  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n4  [{'origin': {'type': 'locode', 'name': 'Port o...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ScrapingDate</th>\n      <th>destination_name</th>\n      <th>destination_location</th>\n      <th>destination_locode</th>\n      <th>origin_name</th>\n      <th>origin_location</th>\n      <th>origin_locode</th>\n      <th>totalResults</th>\n      <th>NumberOfLegs</th>\n      <th>totalTravelTimeInMinutes</th>\n      <th>totalDistanceInMeters</th>\n      <th>totalCo2EmissionsInKg</th>\n      <th>voyageStart</th>\n      <th>voyageEnd</th>\n      <th>transferCo2EmissionsInKg</th>\n      <th>legs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>44912</td>\n      <td>12894138</td>\n      <td>1150</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-05T07:02:14+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>30676</td>\n      <td>13132075</td>\n      <td>1860</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-28T02:49:28+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>28258</td>\n      <td>12962474</td>\n      <td>1885</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T10:30:48+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>39330</td>\n      <td>12629105</td>\n      <td>1045</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-01T10:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>27987</td>\n      <td>12804509</td>\n      <td>1750</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T06:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:22:26.723123Z",
     "end_time": "2023-04-02T13:22:26.785911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Save the dataframe to a pickle file.\n",
    "filename = \"routescanner_v2_connections_combined\"\n",
    "df.to_pickle(f\"../pickles/{filename}.pickle\")\n",
    "df.to_csv(f\"../data/{filename}.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:22:26.754659Z",
     "end_time": "2023-04-02T13:22:29.322653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  ScrapingDate destination_name                 destination_location  \\\n0   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n1   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n2   2022-10-31        Amsterdam    {'lat': 52.37403, 'lng': 4.88969}   \n3   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n4   2022-10-31  Port of Antwerp  {'lat': 51.249596, 'lng': 4.407942}   \n\n  destination_locode    origin_name                        origin_location  \\\n0              NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n1              NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n2              NLAMS  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n3              BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n4              BEANR  Port of Arica  {'lat': -18.474563, 'lng': -70.32761}   \n\n  origin_locode  totalResults  NumberOfLegs  totalTravelTimeInMinutes  \\\n0         CLARI             3             3                     44912   \n1         CLARI             3             3                     30676   \n2         CLARI             3             3                     28258   \n3         CLARI             2             2                     39330   \n4         CLARI             2             2                     27987   \n\n   totalDistanceInMeters  totalCo2EmissionsInKg                voyageStart  \\\n0               12894138                   1150  2022-11-03T22:30:00-03:00   \n1               13132075                   1860  2022-11-06T13:32:30-05:00   \n2               12962474                   1885  2022-11-06T13:32:30-05:00   \n3               12629105                   1045  2022-11-03T22:30:00-03:00   \n4               12804509                   1750  2022-11-06T13:32:30-05:00   \n\n                   voyageEnd transferCo2EmissionsInKg  \\\n0  2022-12-05T07:02:14+01:00                 [15, 15]   \n1  2022-11-28T02:49:28+01:00                 [15, 15]   \n2  2022-11-26T10:30:48+01:00                 [15, 15]   \n3  2022-12-01T10:00:00+01:00                     [15]   \n4  2022-11-26T06:00:00+01:00                     [15]   \n\n                                                legs  \n0  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n1  [{'origin': {'type': 'locode', 'name': 'Port o...  \n2  [{'origin': {'type': 'locode', 'name': 'Port o...  \n3  [{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...  \n4  [{'origin': {'type': 'locode', 'name': 'Port o...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ScrapingDate</th>\n      <th>destination_name</th>\n      <th>destination_location</th>\n      <th>destination_locode</th>\n      <th>origin_name</th>\n      <th>origin_location</th>\n      <th>origin_locode</th>\n      <th>totalResults</th>\n      <th>NumberOfLegs</th>\n      <th>totalTravelTimeInMinutes</th>\n      <th>totalDistanceInMeters</th>\n      <th>totalCo2EmissionsInKg</th>\n      <th>voyageStart</th>\n      <th>voyageEnd</th>\n      <th>transferCo2EmissionsInKg</th>\n      <th>legs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>44912</td>\n      <td>12894138</td>\n      <td>1150</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-05T07:02:14+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>30676</td>\n      <td>13132075</td>\n      <td>1860</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-28T02:49:28+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-10-31</td>\n      <td>Amsterdam</td>\n      <td>{'lat': 52.37403, 'lng': 4.88969}</td>\n      <td>NLAMS</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>3</td>\n      <td>3</td>\n      <td>28258</td>\n      <td>12962474</td>\n      <td>1885</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T10:30:48+01:00</td>\n      <td>[15, 15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>39330</td>\n      <td>12629105</td>\n      <td>1045</td>\n      <td>2022-11-03T22:30:00-03:00</td>\n      <td>2022-12-01T10:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'uuid': 'a9d25a4a-a784-417b-8196-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-10-31</td>\n      <td>Port of Antwerp</td>\n      <td>{'lat': 51.249596, 'lng': 4.407942}</td>\n      <td>BEANR</td>\n      <td>Port of Arica</td>\n      <td>{'lat': -18.474563, 'lng': -70.32761}</td>\n      <td>CLARI</td>\n      <td>2</td>\n      <td>2</td>\n      <td>27987</td>\n      <td>12804509</td>\n      <td>1750</td>\n      <td>2022-11-06T13:32:30-05:00</td>\n      <td>2022-11-26T06:00:00+01:00</td>\n      <td>[15]</td>\n      <td>[{'origin': {'type': 'locode', 'name': 'Port o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"../pickles/routescanner_v2_connections_combined.pickle\").head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-02T13:22:29.322653Z",
     "end_time": "2023-04-02T13:22:30.439815Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
